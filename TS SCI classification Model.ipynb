{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e807ac",
   "metadata": {},
   "source": [
    "# TS SCI Classification Model \n",
    "\n",
    "## edited: 5 July 23\n",
    "\n",
    "## author: Angus Ferrell\n",
    "\n",
    "### 1. Initiliaze functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "f4c8d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load general utilities\n",
    "# ----------------------\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.axes as ax\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns\n",
    "import statistics as stat\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "# Load sklearn utilities\n",
    "# ----------------------\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_auc_score, roc_curve, brier_score_loss, mean_squared_error, r2_score, recall_score, precision_score,f1_score\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load classifiers\n",
    "# ----------------\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Other Packages\n",
    "# --------------\n",
    "from scipy.stats import kendalltau\n",
    "from sklearn.cluster import KMeans\n",
    "from io import StringIO\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from scipy.interpolate import BSpline\n",
    "\n",
    "# Load debugger, if required\n",
    "#import pixiedust\n",
    "pd.options.mode.chained_assignment = None #'warn'\n",
    "\n",
    "# suppress all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#set random_state\n",
    "random_state=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "id": "99abc6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check Job Title\n",
    "# Imported from TECH VIP file\n",
    "\n",
    "file_name = 'TECH VIP results.csv'\n",
    "column_to_filter = 'title_1'\n",
    "\n",
    "def check_jobtitle(data):\n",
    "    #data = pd.read_csv(file_name, engine = 'python', error_bad_lines = False)\n",
    "    \n",
    "    pos = pd.read_csv('TECH VIP/positive ts.csv').dropna(subset=['Keyword'])\n",
    "    neg = pd.read_csv('TECH VIP/negative.csv').dropna(subset=['Keyword'])\n",
    "\n",
    "    pos_keys = pos.get('Keyword').tolist()\n",
    "    pos_keys = [item.lower().strip() for item in pos_keys]\n",
    "\n",
    "\n",
    "    neg_keys = neg.get('Keyword').tolist()\n",
    "    neg_keys = [item.lower().strip() for item in neg_keys]\n",
    "\n",
    "\n",
    "    it_keys = ['izzt ', ' izzt', ' izzt '] #Get IT titles\n",
    "    \n",
    "    pos_keys.append('izzt ')\n",
    "    pos_keys.append(' izzt')\n",
    "    pos_keys.append(' izzt ')\n",
    "\n",
    "    pos_keys.append('cto ')\n",
    "    pos_keys.append(' cto')\n",
    "    pos_keys.append(' cto ')\n",
    "\n",
    "    pp = \"|\".join(pos_keys)\n",
    "    nn = \"|\".join(neg_keys)\n",
    "    \n",
    "    df = data\n",
    "    specified_column_1 = column_to_filter #CHANGE SPECIFIED COLUMN HEADER FOR FILTER\n",
    "    df[specified_column_1] = df[specified_column_1].fillna('')\n",
    "    #df = df.dropna(subset=[specified_column_1])\n",
    "\n",
    "    pos_index = []\n",
    "    neg_index = []\n",
    "\n",
    "    for col in df[specified_column_1].items():\n",
    "        pattern = re.compile(pp)\n",
    "        stri = col[1].lower()\n",
    "        find_pat = pattern.findall(stri,0,len(stri))\n",
    "        if len(find_pat) >= 1:\n",
    "            pos_index.append(col[0])\n",
    "\n",
    "    #df['job title_index'] = df.loc[pos_index] \n",
    "    \n",
    "    data['job_index'] = 0  # Create a new column 'job_index' initialized with 0\n",
    "    data.loc[pos_index, 'job_index'] = 1 \n",
    "    \n",
    "    for col in df[specified_column_1].items():\n",
    "        pattern = re.compile(nn)\n",
    "        stri = col[1].lower()\n",
    "        find_pat = pattern.findall(stri,0,len(stri))\n",
    "        if len(find_pat) >= 1:\n",
    "            neg_index.append(col[0])\n",
    "            \n",
    "    data.loc[neg_index, 'job_index'] = -1 \n",
    "    \n",
    "    print('Job title - number of pos matches: ', len(pos_index))\n",
    "    #print('Job title - number of neg matches: ', len(neg_index))\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "id": "92e91b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check company\n",
    "\n",
    "company_list = ['General Dynamics Information Technology', 'Gridiron IT Solutions', 'SAIC', 'SPA', \n",
    "                'Institute For Defense Analyses', 'IC-CAP', 'Peraton', 'ManTech', 'Tyto Athene LLC',\n",
    "                'Boeing Intelligence & Analytics', 'Arcfield', 'Leidos', 'Raytheon Technologies', 'CACI', \n",
    "                'Booz Allen Hamilton', 'Lockheed Martin', 'ALTA IT Services', 'Cyber Defense Technologies', \n",
    "                'TekMasters', 'Emerald Technical Solutions', 'Modern Technology Solutions Inc.', 'VTG', \n",
    "                'MITRE Corporation', 'SRG Government Services', 'ManTech International', 'MAXAR Technologies',\n",
    "                'Leidos', 'Parsons', 'BAE Systems', 'Marathon TS Inc', 'Guidehouse', 'SilverEdge', 'MC Dean Inc', \n",
    "                'Trevity LLC', 'teKnoluxion Consulting', 'Northrop Grumman', 'Sentar Inc', 'Stellar Solutions', \n",
    "                'Criterion Systems Inc', 'IntelliGenesis LLC', 'LMI Government Consulting', 'MAG Aero', \n",
    "                'HII Mission Technologies', 'Enlighten', 'In Technology Group Limited', 'ProSync Technology Group',\n",
    "                'Connsci', 'Signature Federal Systems', 'Apex Systems', 'Buchanan and Edwards',\n",
    "                'Radiance Technologies', 'Noblis', 'SRG Government Services', 'Xcelerate Solutions', \n",
    "                'DCS Corporation', 'Associates Systems LLC', 'BlueHalo', 'Strategic Alliance Consulting Inc',\n",
    "                'IT Concepts Inc', 'Barbaricum', 'Forcepoint', 'Federal IT Consulting', 'Canvas Inc', \n",
    "                'TEKsystems c/o Allegis Group', 'iota IT', 'Illuminate Operations Inc', 'Compass Inc', \n",
    "                'Applied Research Solutions', 'Avineon Inc', 'I3 LLC', 'Assured Information Security Inc',\n",
    "                'hyrUP', 'Millennium Corporation', 'Core One', 'TekSynap', 'Base-2 Solutions LLC', 'AERMOR', \n",
    "                'Amentum', 'Cornerstone Defense', 'Base One Technologies', 'ALTA IT Services', 'Sentar Inc', \n",
    "                'Ennoble First', 'Core4ce', 'Syntelligent Analytic Solutions LLC', 'Serco Inc', \n",
    "                'Space Dynamics Laboratory', 'RDR Inc', 'MicroTech LLC', 'North Point Technology LLC', \n",
    "                'LinQuest Corporation', 'Kavaliro', 'SOSi', 'Allen Integrated Solutions LLC',\n",
    "                'Columbia Technology Partners', 'Dark Wolf Solutions', 'Strategic Alliance Consulting Inc',\n",
    "                'MAXAR Technologies', 'AT&T Government Solutions', 'Invictus International Consulting', \n",
    "                'Secure Halo', 'Octo', 'Lumen', 'Applied Insight', 'PeopleTec', 'NASK', 'Highlight Technologies',\n",
    "                'JCTM Joint Computer Technologies & Training Management', 'ClearEdge IT Solutions LLC',\n",
    "                'Echelon Services LLC', 'Clear Resolution Consulting LLC', 'American Systems Corporation', \n",
    "                'Abile Group', 'KBR', 'Abbtech Professional Resources Inc', 'Stanley Reid & Company', \n",
    "                'Stillwater Human Capital', 'Fluor Corporation', 'Chenega Corporation', 'RMGS Inc', \n",
    "                'Moseley Technical Services Inc', 'Personnel Impact Inc', 'Rividium Inc', 'Edgesource',\n",
    "                'Sunayu LLC', 'SSATI', 'Distributed Solutions Inc', 'Information Gateways Inc', 'ENSCO Inc',\n",
    "                'Independent Software', 'Avantus Federal', 'Strategic ASI', 'IOMAXIS LLC', \n",
    "                'StraCon Services Group LLC', 'Railhead Inc', 'CONNEXIONS FEDERAL SERVICES', \n",
    "                'Valiant Integrated Services', 'Intelligent Waves', 'Maximus Inc', 'Thresher Corporation',\n",
    "                'Market Street Talent', 'Odyssey Systems Consulting Group', 'Quantum Research International Inc',\n",
    "                'Dezign-Concepts', 'The DarkStar Group', 'Red River Technology LLC', 'Mission Box Solutions',\n",
    "                'Executive Management Services LLC', 'The Global Edge Consultants', 'TRIAEM LLC',\n",
    "                'Delta Solutions and Strategies LLC', 'Intrepid Solutions and Services LLC', 'FiveTwelve LLC',\n",
    "                'CACI International Inc', 'Raytheon', 'Deloitte','Oshkosh', 'Boeing','Accenture Federal Services',\n",
    "                'Palantir Technologies','US Army','US Navy','United States Air Force','Department of Defense','USAF']\n",
    "\n",
    "\n",
    "#'Microsoft','Amazon', 'Google','Amazon Web Services (AWS)']\n",
    "\n",
    "military_pattern = r'US Army|US Navy|air force|usaf|marines|special operations|special forces| socom |Department of Defense| DoD '\n",
    "\n",
    "#gov_pattern = r'Central Intelligence Agency|CIA|National Security Agency|NSA|Federal Bureau of Investigation|FBI|Department of State|Department of Homeland Security|DHS|Defense Intelligence Agency|DIA|National Reconnaissance Office|NRO|National Geospatial-Intelligence Agency|NGA|United States Secret Service|Drug Enforcement Administration|DEA|National Counterterrorism Center|NCTC|Bureau of Alcohol, Tobacco, Firearms, and Explosives|ATF|Department of Energy|DOE|Department of Justice|DOJ'\n",
    "                    # FBI | NSA | DOJ | CIA | DHS | DIA \n",
    "\n",
    "\n",
    "def check_company(df):\n",
    "\n",
    "    # Fill missing values with an empty string\n",
    "    df['company_1'] = df['company_1'].fillna('NaN')\n",
    "    df['company_2'] = df['company_2'].fillna('NaN')\n",
    "    df['company_1'] = df['company_1'].replace('U.S. Navy', 'US Navy')\n",
    "    df['company_2'] = df['company_2'].replace('U.S. Navy', 'US Navy')\n",
    "    df['company_1'] = df['company_1'].replace('U.S. Army', 'US Army')\n",
    "    df['company_2'] = df['company_2'].replace('U.S. Army', 'US Army')\n",
    "    df['company_1'] = df['company_1'].replace('CACI', 'CACI International Inc')\n",
    "    df['company_2'] = df['company_2'].replace('CACI', 'CACI International Inc')\n",
    "    df['company_1'] = df['company_1'].replace('Raytheon', 'Raytheon Technologies')\n",
    "    df['company_2'] = df['company_2'].replace('Raytheon', 'Raytheon Technologies')\n",
    "    df['company_1'] = df['company_1'].replace('Northrop Grumman Corporation', 'Northrop Grumman')\n",
    "    df['company_2'] = df['company_2'].replace('Northrop Grumman Corporation', 'Northrop Grumman')\n",
    "    df['company_1'] = df['company_1'].replace('Palantir', 'Palantir Technologies')\n",
    "    df['company_2'] = df['company_2'].replace('Palantir', 'Palantir Technologies')\n",
    "    \n",
    "    \n",
    "    #Apply regex pattern to filter DataFrame\n",
    "    df['company_index'] = df.apply(lambda row: int(1) if row['company_1'] in company_list or \n",
    "                                   re.search(military_pattern, row['company_1'], re.IGNORECASE) \n",
    "                                   else int(0), axis=1)\n",
    "    \n",
    "    #df['company_index'] = df.apply(calculate_company_index, axis=1)\n",
    "    print('Company - Number of matches: ', np.sum(df.company_index==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "id": "b3a592eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check skills\n",
    "\n",
    "# Regex pattern\n",
    "skills_pattern = r'TS CLEARANCE|TS/SCI|TOP SECRET CLEARANCE|ACTIVE TS CLEARANCE| TS SCI |TS SCI CLEARANCE|POLYGRAPGH| CI POLY|FULL SCOPE POLY'\n",
    "\n",
    "def check_skills(df):\n",
    "\n",
    "    # Fill missing values with an empty string\n",
    "    df['Skills'] = df['Skills'].fillna('')\n",
    "    \n",
    "     # Apply regex pattern to filter DataFrame\n",
    "    df['skills_index'] = df.apply(lambda row: 1 if re.search(skills_pattern, row['Skills'], \n",
    "                                                             re.IGNORECASE) else 0, axis=1)\n",
    "\n",
    "    print('Skills - Number of matches: ', np.sum(df.skills_index==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "id": "e8f4c44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check summary\n",
    "\n",
    "def check_summary(df):\n",
    "    \n",
    "    # Fill missing values with an empty string\n",
    "    df['Summary'] = df['Summary'].fillna('')\n",
    "\n",
    "    # Apply regex pattern to filter DataFrame\n",
    "    df['summary_index'] = df.apply(lambda row: 1 if re.search(skills_pattern, row['Summary'], \n",
    "                                                              re.IGNORECASE) else 0, axis=1)\n",
    "\n",
    "    print('Summary - Number of matches: ', np.sum(df.summary_index==1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "id": "b62a8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check job description\n",
    "\n",
    "\n",
    "def check_desc(df):\n",
    "    \n",
    "    # Fill missing values with an empty string\n",
    "    df['Job_Description_1'] = df['Job_Description_1'].fillna('')\n",
    "    #df['Job_Description_2'] = df['Job_Description_2'].fillna('')\n",
    "\n",
    "    # Apply regex pattern to filter DataFrame\n",
    "    df['desc_index'] = df.apply(lambda row: 1 if re.search(skills_pattern, row['Job_Description_1'], \n",
    "                                                              re.IGNORECASE) else 0, axis=1)\n",
    "\n",
    "    print('Description - Number of matches: ', np.sum(df.desc_index==1))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "id": "81738fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check location based on states with highest liklihood of TS \n",
    "\n",
    "popular_states = ['Virginia','Maryland','California','District of Columbia','Florida','Colorado','Utah','Texas',\n",
    "                 'Alabama','New Mexico','Ohio','Georgia','Hawaii', 'North Carolina','South Carolina', 'Arizona',\n",
    "                  'Washington']\n",
    "\n",
    "\n",
    "def check_location(df):\n",
    "    \n",
    "     # Fill missing values with an empty string\n",
    "    df['State'] = df['State'].fillna('')\n",
    "\n",
    "    # Apply regex pattern to filter DataFrame\n",
    "    df['location_index'] = df.apply(lambda row: 1 if row['State'] in popular_states else 0, axis=1)\n",
    "    \n",
    "   \n",
    "    print('Location - Number of matches: ', np.sum(df.location_index==1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "id": "0500ffe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check names\n",
    "# using 2000 most common US census data names\n",
    "\n",
    "common_names = pd.read_csv('common_names.csv').dropna(subset=['Keyword'])\n",
    "\n",
    "name_list = []\n",
    "\n",
    "for name in common_names.Keyword:\n",
    "    name_list.append(name)\n",
    "\n",
    "\n",
    "def check_name(df):\n",
    "    \n",
    "     # Fill missing values with an empty string\n",
    "    df['First Name'] = df['First Name'].fillna('')\n",
    "\n",
    "    # Apply regex pattern to filter DataFrame\n",
    "    df['name_index'] = df.apply(lambda row: 1 if row['First Name'].upper() in name_list else 0, axis=1)\n",
    "    \n",
    "   \n",
    "    print('Names - Number of matches: ', np.sum(df.name_index==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "id": "04e0cfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this code creates an equal number of positive and random cases from the imported dataset\n",
    "#then creates the respective class labels\n",
    "#returns a training data dataframe and labels array\n",
    "\n",
    "def create_trainingdata(data,random_state = random_state):\n",
    "    \n",
    "    #check_skills(data)\n",
    "    #check_summary(data)\n",
    "    #check_desc(data)\n",
    "\n",
    "    #summary_df = data[data.summary_index == 1]\n",
    "    #skills_df = data[data.skills_index == 1]\n",
    "    #desc_df = data[data.desc_index == 1]\n",
    "\n",
    "    #training_data = pd.concat([summary_df, skills_df, desc_df])\n",
    "    #training_data = training_data[columns]\n",
    "    \n",
    "    columns = ['Linkedin_url','Summary', 'Skills', 'title_1',\n",
    "       'company_1', 'time_duration_1', 'Job_Description_1', 'title_2',\n",
    "       'company_2', 'time_duration_2', 'Job_Description_2', \n",
    "       'First Name','Middle Name', 'Surname', 'City', 'State', 'Country']\n",
    "    \n",
    "    training_data = check_for_keywords(data)\n",
    "    training_data = training_data[columns]\n",
    "    \n",
    "    val_labels = np.ones(len(training_data))\n",
    "\n",
    "    num_numbers = len(training_data)\n",
    "    min_num = 1\n",
    "    max_num = len(data)\n",
    "\n",
    "    training_data_indices = training_data.index\n",
    "    \n",
    "    random_generator = random.Random(random_state)\n",
    "\n",
    "    '''\n",
    "    random_numbers = []\n",
    "    while len(random_numbers) < num_numbers:\n",
    "        random_num = random_generator.randint(min_num, max_num)\n",
    "        if random_num not in training_data_indices:\n",
    "            random_numbers.append(random_num)\n",
    "     '''       \n",
    "\n",
    "    random_numbers = []\n",
    "    target_length = 4 * num_numbers\n",
    "\n",
    "    while len(random_numbers) < target_length:\n",
    "        random_numbers.append(random_generator.randint(min_num, max_num))\n",
    "        \n",
    "\n",
    "    random_data_df = data.loc[random_numbers, columns]\n",
    "    random_data_indices = random_data_df.index\n",
    "\n",
    "    random_labels = np.zeros(len(random_numbers))\n",
    "\n",
    "    training_data_df = pd.concat([training_data, random_data_df])\n",
    "    training_data_labels = np.append(val_labels, random_labels)\n",
    "\n",
    "    x_unlabeled_indices = data.index.difference(training_data_indices.union(random_data_indices))\n",
    "    x_unlabeled_df = data.loc[x_unlabeled_indices, columns]\n",
    "\n",
    "    return training_data_df, training_data_labels, x_unlabeled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "id": "859b94f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_for_keywords(df):\n",
    "    \n",
    "    keywords = ['TS CLEARANCE','TS/SCI','TOP SECRET CLEARANCE','ACTIVE TS CLEARANCE', 'TS SCI','TS SCI CLEARANCE','POLYGRAPH','CI POLY','FULL SCOPE POLY']\n",
    "    keyword_rows = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        for column in df.columns:\n",
    "            cell_value = str(row[column]).upper()\n",
    "            if any(keyword in cell_value for keyword in keywords):\n",
    "                keyword_rows.append(index)\n",
    "                break  # Move to the next row if keyword found in any column\n",
    "\n",
    "    print('# matches: ',len(keyword_rows))   \n",
    "    \n",
    "    output = df.iloc[keyword_rows]\n",
    "    \n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "id": "21a6dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that, given a CVGridSearch object, finds the\n",
    "# percentage difference between the best and worst scores\n",
    "def find_score_variation(cv_model):\n",
    "    all_scores = cv_model.cv_results_['mean_test_score']\n",
    "    return( np.abs((max(all_scores) - min(all_scores))) * 100 / max(all_scores) )\n",
    "\n",
    "\n",
    "# Define a function that checks, given a CVGridSearch object,\n",
    "# whether the optimal parameters lie on the edge of the search\n",
    "# grid\n",
    "def find_opt_params_on_edge(cv_model):\n",
    "    out = False\n",
    "    \n",
    "    for i in cv_model.param_grid:\n",
    "        if cv_model.best_params_[i] in [ cv_model.param_grid[i][0], cv_model.param_grid[i][-1] ]:\n",
    "            out = True\n",
    "            break\n",
    "            \n",
    "    return out\n",
    "\n",
    "\n",
    "default_seed = 0\n",
    "output_file = \"output_sample\"\n",
    "\n",
    "# Create a function to print a line to our output file\n",
    "\n",
    "def dump_to_output(key, value):\n",
    "    with open(output_file, \"a\") as f:\n",
    "        f.write(\",\".join([str(default_seed), key, str(value)]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "id": "a5d53ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_classification(model, X_train,y_train, X_test, y_test,\n",
    "                          cv_parameters = {},\n",
    "                          model_name = None,\n",
    "                          random_state = 0,\n",
    "                          output_to_file = True,\n",
    "                          print_to_screen = True):\n",
    "    \n",
    "    np.random.seed(random_state)\n",
    "\n",
    "    # --------------------------\n",
    "    #   Step 2 - Fit the model\n",
    "    # --------------------------\n",
    "\n",
    "    cv_model = GridSearchCV(model, cv_parameters)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    cv_model.fit(X_train, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    best_model = cv_model.best_estimator_\n",
    "    \n",
    "    if print_to_screen:\n",
    "\n",
    "        if model_name != None:\n",
    "            print(\"=========================================================\")\n",
    "            print(\"  Model: \" + model_name)\n",
    "            print(\"=========================================================\")\n",
    "\n",
    "        print(\"Fit time: \" + str(round(end_time - start_time, 2)) + \" seconds\")\n",
    "        print(\"Optimal parameters:\")\n",
    "        print(cv_model.best_params_)\n",
    "        print(\"\")\n",
    "    \n",
    "    # -------------------------------\n",
    "    #   Step 3 - Evaluate the model\n",
    "    # -------------------------------\n",
    "    \n",
    "    # If possible, make probability predictions\n",
    "    try:\n",
    "        y_pred_probs = best_model.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_pred_probs)\n",
    "        \n",
    "        probs_predicted = True\n",
    "    except:\n",
    "        probs_predicted = False\n",
    "    \n",
    "    # Make predictions; if we were able to find probabilities, use\n",
    "    # the threshold that maximizes the accuracy in the training set.\n",
    "    # If not, just use the learner's predict function\n",
    "    if probs_predicted:\n",
    "        y_train_pred_probs = best_model.predict_proba(X_train)[:,1]\n",
    "        fpr_train, tpr_train, thresholds_train = roc_curve(y_train, y_train_pred_probs)\n",
    "        \n",
    "        true_pos_train = tpr_train*(y_train.sum())\n",
    "        true_neg_train = (1 - fpr_train) *(1-y_train).sum()\n",
    "        \n",
    "        best_threshold_index = np.argmax(true_pos_train + true_neg_train)\n",
    "        best_threshold = 1 if best_threshold_index == 0 else thresholds_train[ best_threshold_index ]\n",
    "        \n",
    "        if print_to_screen:\n",
    "            print(\"Accuracy-maximizing threshold was: \" + str(best_threshold))\n",
    "        \n",
    "        y_pred = (y_pred_probs > best_threshold)\n",
    "    else:\n",
    "        y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    if print_to_screen:\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "        print(classification_report(y_test, y_pred, target_names =['No default', 'Default'], digits = 4))\n",
    "\n",
    "    if print_to_screen:\n",
    "        if probs_predicted:        \n",
    "            plt.figure(figsize = (13, 4.5))\n",
    "            plt.subplot(2, 2, 1)\n",
    "\n",
    "            plt.title(\"ROC Curve (AUC = %0.2f)\"% roc_auc_score(y_test, y_pred_probs))\n",
    "            plt.plot(fpr, tpr, 'b')\n",
    "            plt.plot([0,1],[0,1],'r--')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.ylabel('True Positive Rate')\n",
    "            plt.xlabel('False Positive Rate')\n",
    "\n",
    "            plt.subplot(2, 2, 3)\n",
    "\n",
    "            plt.plot(thresholds, tpr, 'b', label = 'Sensitivity')\n",
    "            plt.plot(thresholds, 1 -fpr, 'r', label = 'Specificity')\n",
    "            plt.legend(loc = 'lower right')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.xlabel('Threshold')\n",
    "\n",
    "            plt.subplot(2, 2, 2)\n",
    "\n",
    "            fp_0, mpv_0 = calibration_curve(y_test, y_pred_probs, n_bins = 10)\n",
    "            plt.plot([0,1], [0,1], 'k:', label='Perfectly calibrated')\n",
    "            plt.plot(mpv_0, fp_0, 's-')\n",
    "            plt.ylabel('Fraction of Positives')\n",
    "            plt.xlim([0,1]); plt.ylim([0,1])\n",
    "            plt.legend(loc ='upper left')\n",
    "            \n",
    "            plt.subplot(2, 2, 4)\n",
    "            plt.hist(y_pred_probs, range=(0, 1), bins=10, histtype=\"step\", lw=2)\n",
    "            plt.xlim([0,1]); plt.ylim([0,20000])\n",
    "            plt.xlabel('Mean Predicted Probability')\n",
    "            plt.ylabel('Count')\n",
    "            \n",
    "            #plt.tight_layout()\n",
    "            plt.show()\n",
    "        \n",
    "    # Additional Score Check\n",
    "    if probs_predicted:\n",
    "        y_train_score = y_train_pred_probs\n",
    "    else:\n",
    "        y_train_score = best_model.decision_function(X_train)\n",
    "        \n",
    "    #tau, p_value = kendalltau(y_train_score, data.grade[filter_train])\n",
    "    #if print_to_screen:\n",
    "        #print(\"\")\n",
    "        #print(\"Similarity to LC grade ranking: \", tau)\n",
    "    \n",
    "    if probs_predicted:\n",
    "        brier_score = brier_score_loss(y_test, y_pred_probs)\n",
    "        if print_to_screen:\n",
    "            print(\"Brier score:\", brier_score)\n",
    "    \n",
    "    # Return the model predictions, and the\n",
    "    # test set\n",
    "    # -------------------------------------\n",
    "    out = {'model':best_model, 'y_pred_labels':y_pred}\n",
    "    \n",
    "    if probs_predicted:\n",
    "        out.update({'y_pred_probs':y_pred_probs})\n",
    "    else:\n",
    "        y_pred_score = best_model.decision_function(X_test)\n",
    "        out.update({'y_pred_score':y_pred_score})\n",
    " \n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefa3122",
   "metadata": {},
   "source": [
    "### 2. Build Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "344c2b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['updated_datasets/updated_lifull_12.2022.csv', 'updated_datasets/updated_lifull_419M3.csv', 'updated_datasets/updated_lifull_419_M2.csv', 'updated_datasets/updated_more_training_data.csv', 'updated_datasets/updated_lifull_419M1.csv', 'updated_datasets/updated_lifull_bing2_212.csv', 'updated_datasets/updated_lifull_322_0.csv', 'updated_datasets/updated_li_full_11_22.csv', 'updated_datasets/updated_lifull_303.csv', 'updated_datasets/updated_lifull_326-001.csv', 'updated_datasets/updated_lifull_bing1_212.csv', 'updated_datasets/updated_lifull_326-000.csv', 'updated_datasets/updated_lifull_326-002.csv', 'updated_datasets/updated_lifull_reg_212.csv', 'updated_datasets/updated_lifull_1_2023.csv', 'updated_datasets/updated_lifull_309_1.csv', 'updated_datasets/updated_lifull_309_2_3.csv']\n"
     ]
    }
   ],
   "source": [
    "training_files = glob.glob('updated_datasets/*.csv')\n",
    "print(training_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "f05adbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# matches:  399\n",
      "# matches:  508\n",
      "# matches:  703\n",
      "# matches:  4106\n",
      "# matches:  616\n",
      "# matches:  373\n",
      "# matches:  358\n",
      "# matches:  386\n",
      "# matches:  481\n",
      "# matches:  398\n",
      "# matches:  361\n",
      "# matches:  393\n",
      "# matches:  326\n",
      "# matches:  260\n",
      "# matches:  601\n",
      "# matches:  333\n",
      "# matches:  473\n",
      "number of training sets:  17\n"
     ]
    }
   ],
   "source": [
    "training_df = []\n",
    "labels = []\n",
    "unlabeled_list = []\n",
    "\n",
    "for filename in training_files:\n",
    "    # Call create_trainingdata function\n",
    "    data = pd.read_csv(filename) \n",
    "    df, label, unlabeled = create_trainingdata(data,random_state)\n",
    "    \n",
    "    # Append dataframe and label to respective lists\n",
    "    training_df.append(df)\n",
    "    labels.append(label)\n",
    "    unlabeled_list.append(unlabeled)\n",
    " \n",
    "print('number of training sets: ',len(training_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "id": "6204ad24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data:  (55375, 17)\n",
      "training data labels:  (55375,)\n",
      "unlabeled data:  (3119785, 17)\n"
     ]
    }
   ],
   "source": [
    "### Combine all training data ###\n",
    "\n",
    "#training_df.append(training_data)\n",
    "#labels.append(training_labels)\n",
    "\n",
    "training_data_new = pd.concat(training_df)\n",
    "\n",
    "training_data_new.fillna({'connections':0, 'company_1':'NaN', 'company_2':'NaN',\n",
    "                    'company_3':'NaN', 'company_4':'NaN', 'Summary':'','Skills':'','Job_Description_1':'',\n",
    "                    'First Name':'','Surname':'','State':'','title_1':'',\n",
    "                    'title_2':'', 'Surname':'', 'City':'', 'Country':''}, inplace=True)\n",
    "\n",
    "print('training data: ', training_data_new.shape)\n",
    "\n",
    "training_labels_new = np.concatenate(labels)\n",
    "print('training data labels: ', training_labels_new.shape)\n",
    "\n",
    "X_unlabeled = pd.concat(unlabeled_list)\n",
    "print('unlabeled data: ', X_unlabeled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "ba08d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove invalid labels \n",
    "\n",
    "training_labels_new[training_data_new['company_1']=='NaN'] = 0\n",
    "training_labels_new[training_data_new['company_1']=='Retired'] = 0\n",
    "training_labels_new[training_data_new['company_1']=='Self-employed'] = 0\n",
    "training_labels_new[training_data_new['company_1']=='USAA'] = 0\n",
    "training_labels_new[training_data_new['company_1']=='Wells Fargo'] = 0\n",
    "\n",
    "countries = ['United States']\n",
    "training_labels_new[~training_data_new['Country'].isin(countries)] = 0\n",
    "\n",
    "keywords = ['fitness','gym', 'health', 'therapeutic','finance']\n",
    "mask = training_data_new['company_1'].str.lower().str.contains('|'.join(keywords))\n",
    "training_labels_new[mask] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6961a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write out training data\n",
    "'''\n",
    "df_out = training_data_new\n",
    "df_out['Label'] = training_labels_new\n",
    "df_out.to_csv('training data.csv', index=False)\n",
    "\n",
    "\n",
    "\n",
    "#write out all data\n",
    "training_files = glob.glob('datasets/*.csv')\n",
    "print(training_files)\n",
    "\n",
    "files = []\n",
    "for filename in training_files:\n",
    "    data = pd.read_csv(filename)\n",
    "    files.append(data)\n",
    "    \n",
    "filename_out = 'Combined__datasets.csv'\n",
    "combined_data = pd.concat(files, ignore_index=True)\n",
    "combined_data.to_csv(filename_out, index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05726cf6",
   "metadata": {},
   "source": [
    "### 3. Train Classifier Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "id": "bc064039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job title - number of pos matches:  864\n",
      "Company - Number of matches:  2616\n",
      "Skills - Number of matches:  179\n",
      "Summary - Number of matches:  5927\n",
      "Description - Number of matches:  359\n",
      "Location - Number of matches:  13341\n",
      "Names - Number of matches:  16508\n",
      "(19935, 7)\n",
      "(19935,)\n",
      "(2215, 7)\n",
      "(2215,)\n"
     ]
    }
   ],
   "source": [
    "#create training splits for model\n",
    "\n",
    "#random_state = 0\n",
    "\n",
    "check_jobtitle(training_data_new)\n",
    "check_company(training_data_new)\n",
    "check_skills(training_data_new)\n",
    "check_summary(training_data_new)\n",
    "check_desc(training_data_new)\n",
    "check_location(training_data_new)\n",
    "check_name(training_data_new)\n",
    "\n",
    "training_data_final = training_data_new[['job_index', 'company_index','skills_index','summary_index','location_index'\n",
    "                                    ,'name_index','desc_index']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data_final, training_labels_new, test_size=0.1, \n",
    "                                                    random_state=random_state)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53f20a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for collinearity\n",
    "\n",
    "df = training_data_final\n",
    "df['Target'] = training_labels_new\n",
    "\n",
    "# Calculate correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(\"Correlation Matrix:\")\n",
    "print(correlation_matrix)\n",
    "\n",
    "training_data_final = training_data_final.drop(columns=['Target'])\n",
    "scaler = StandardScaler()\n",
    "scaled_X = scaler.fit_transform(training_data_final)\n",
    "\n",
    "# Calculate VIF\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = training_data_final.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(scaled_X, i) for i in range(scaled_X.shape[1])]\n",
    "\n",
    "print(\"\\nVariance Inflation Factor (VIF):\")\n",
    "print(vif)\n",
    "\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(scaled_X)\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "print(\"\\nExplained Variance Ratio:\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"Principal Component {i+1}: {ratio:.4f}\")\n",
    "\n",
    "variable_names = training_data_final.columns\n",
    "\n",
    "loadings = pca.components_\n",
    "\n",
    "# Display loadings for each principal component\n",
    "print(\"\\nPrincipal Component Loadings:\")\n",
    "for i, loading in enumerate(loadings):\n",
    "    print(f\"Principal Component {i+1}:\")\n",
    "    for j, weight in enumerate(loading):\n",
    "        print(f\"{variable_names[j]}: {weight:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d53db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=random_state, \n",
    "                              max_features='sqrt', min_samples_leaf=1, min_samples_split=2)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print('rfc Accuracy: ',np.mean(y_pred == y_test))\n",
    "print(\"Recall Score: \", recall_score(y_test, y_pred))\n",
    "print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "print(\"F1 score:\", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d44ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importances\n",
    "feature_importances = rfc.feature_importances_\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for feature, importance in zip(X_train.columns, feature_importances):\n",
    "    print(feature, \":\", importance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee97e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and test a random forest classifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100,random_state=random_state)\n",
    "cv_parameters = {'max_depth': [5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 5],\n",
    "    'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "random_forest = fit_classification(random_forest, X_train,y_train, X_test, y_test,\n",
    "                          cv_parameters, model_name = 'Random Forest',output_to_file = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72509cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and test a multi-layer perceptron classifier\n",
    "\n",
    "mlp = MLPClassifier(random_state=random_state)\n",
    "cv_parameters = {'hidden_layer_sizes': (100,500,(500,500)),\n",
    "                'activation':['identity','logistic','tanh','relu'],\n",
    "                 'alpha': [0.0001, 0.001, 0.01],\n",
    "                 'solver': ['lbfgs','sgd','adam']}\n",
    "\n",
    "mlp = fit_classification(mlp, X_train,y_train, X_test, y_test, cv_parameters, 'Multi-Layer Perceptron',\n",
    "                       output_to_file = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671220c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and test a Gradient Boosting Classifier\n",
    "\n",
    "GradientBoostingClassifier = GradientBoostingClassifier(random_state=random_state)\n",
    "cv_parameters = {\n",
    "    'n_estimators': [100, 500],  \n",
    "    'learning_rate': [0.01,0.1, 0.5, 1.0],  \n",
    "    'max_depth': [3, 5, 10],\n",
    "    'max_features': [1.0, 'sqrt'],\n",
    "    'min_samples_split': [0.1,0.25,0.5,1.0]\n",
    "}\n",
    "\n",
    "GBC = fit_classification(GradientBoostingClassifier, X_train,y_train, X_test, y_test, cv_parameters, \n",
    "                         'GradientBoostingClassifier', output_to_file = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd12a0a",
   "metadata": {},
   "source": [
    "### 4. Train CatBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "id": "f76b782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job title - number of pos matches:  1349\n",
      "Company - Number of matches:  3515\n",
      "Location - Number of matches:  31358\n",
      "Skills - Number of matches:  180\n",
      "Summary - Number of matches:  6221\n",
      "Description - Number of matches:  375\n",
      "(44300, 10)\n",
      "(44300,)\n",
      "(11075, 10)\n",
      "(11075,)\n"
     ]
    }
   ],
   "source": [
    "### Catboost Training Data ###\n",
    "\n",
    "check_jobtitle(training_data_new)\n",
    "check_company(training_data_new)\n",
    "check_location(training_data_new)\n",
    "check_skills(training_data_new)\n",
    "check_summary(training_data_new)\n",
    "check_desc(training_data_new)\n",
    "#check_name(training_data_new)\n",
    "\n",
    "catboost_columns = ['job_index', 'skills_index','summary_index','location_index','company_index'\n",
    "                    ,'desc_index', 'title_1', 'company_1','State','Country']\n",
    "\n",
    "training_data_final2 = training_data_new[catboost_columns]\n",
    "\n",
    "#'First Name','City','title_2', 'company_2'\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data_final2, training_labels_new, test_size=0.2, \n",
    "                                                    random_state=random_state)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "categorical_features_indices = np.where(X_train.dtypes != int)[0]\n",
    "categorical_features_indices\n",
    "y_train = pd.to_numeric(y_train).astype('int32')\n",
    "y_test = pd.to_numeric(y_test).astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "6252ed18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job title - number of pos matches:  44965\n",
      "Company - Number of matches:  78876\n",
      "Location - Number of matches:  1667746\n",
      "Skills - Number of matches:  0\n",
      "Summary - Number of matches:  0\n",
      "Description - Number of matches:  0\n"
     ]
    }
   ],
   "source": [
    "#clean unlabeled data\n",
    "\n",
    "check_jobtitle(X_unlabeled)\n",
    "check_company(X_unlabeled)\n",
    "check_location(X_unlabeled)\n",
    "check_skills(X_unlabeled)\n",
    "check_summary(X_unlabeled)\n",
    "check_desc(X_unlabeled)\n",
    "\n",
    "X_unlabeled.fillna({'connections':0, 'company_1':'NaN', 'company_2':'NaN',\n",
    "                    'company_3':'NaN', 'company_4':'NaN', 'Summary':'','Skills':'','Job_Description_1':'',\n",
    "                    'First Name':'','Surname':'','State':'','title_1':'',\n",
    "                    'title_2':'', 'Surname':'', 'City':'', 'Country':''}, inplace=True)\n",
    "\n",
    "X_unlabeled = X_unlabeled[catboost_columns]\n",
    "\n",
    "#categorical_features_indices_unlabeled = np.where(X_unlabeled.dtypes != int)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "id": "e8210fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on fold [0/3]\n",
      "\n",
      "bestTest = 0.7066234701\n",
      "bestIteration = 236\n",
      "\n",
      "Training on fold [1/3]\n",
      "\n",
      "bestTest = 0.6935541952\n",
      "bestIteration = 132\n",
      "\n",
      "Training on fold [2/3]\n",
      "\n",
      "bestTest = 0.7011163126\n",
      "bestIteration = 242\n",
      "\n"
     ]
    },
    {
     "ename": "CatBoostError",
     "evalue": "Length of label=3175160 and length of data=3124450 is different.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCatBoostError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/74/37xhv12j1_b0bpxcvmn65x_h0000gn/T/ipykernel_66926/4140106754.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m#CatBoost.fit(X_combined, y_combined, cat_features=categorical_features_indices,verbose=False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m CatBoost.fit(\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mX_combined\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_combined\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_features_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5129\u001b[0m             \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_is_compatible_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss_function'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5131\u001b[0;31m         self._fit(X, y, cat_features, text_features, embedding_features, None, sample_weight, None, None, None, None, baseline, use_best_model,\n\u001b[0m\u001b[1;32m   5132\u001b[0m                   \u001b[0meval_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_description\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose_eval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_period\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5133\u001b[0m                   silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2339\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y may be None only when X is an instance of catboost.Pool or string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2341\u001b[0;31m         train_params = self._prepare_train_params(\n\u001b[0m\u001b[1;32m   2342\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcat_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2343\u001b[0m             \u001b[0mpairs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpairs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_prepare_train_params\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks)\u001b[0m\n\u001b[1;32m   2220\u001b[0m         \u001b[0membedding_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_feature_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membedding_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'embedding_features'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2222\u001b[0;31m         train_pool = _build_train_pool(X, y, cat_features, text_features, embedding_features, pairs,\n\u001b[0m\u001b[1;32m   2223\u001b[0m                                        \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgroup_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpairs_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2224\u001b[0m                                        baseline, column_description)\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_build_train_pool\u001b[0;34m(X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, column_description)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m         train_pool = Pool(X, y, cat_features=cat_features, text_features=text_features, embedding_features=embedding_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n\u001b[0m\u001b[1;32m   1439\u001b[0m                           group_weight=group_weight, subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_pool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, column_description, pairs, delimiter, has_header, ignore_csv_quoting, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m    790\u001b[0m                     )\n\u001b[1;32m    791\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m                 self._init(data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight,\n\u001b[0m\u001b[1;32m    793\u001b[0m                            group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\n\u001b[1;32m    794\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_init\u001b[0;34m(self, data, label, cat_features, text_features, embedding_features, embedding_features_data, pairs, weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, timestamp, feature_names, feature_tags, thread_count)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m                 \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_label_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfeature_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/MLPS/lib/python3.9/site-packages/catboost/core.py\u001b[0m in \u001b[0;36m_check_label_shape\u001b[0;34m(self, label, samples_count)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \"\"\"\n\u001b[1;32m    907\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCatBoostError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Length of label={} and length of data={} is different.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_baseline_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbaseline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCatBoostError\u001b[0m: Length of label=3175160 and length of data=3124450 is different."
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "\n",
    "class_weights = [1,1.5]\n",
    "#class_weights = [1,1]\n",
    "\n",
    "'''\n",
    "CatBoost = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    random_seed=random_state,\n",
    "    learning_rate=0.1,\n",
    "    verbose=False,\n",
    "    class_weights=class_weights,\n",
    "    eval_metric='Precision',\n",
    "    custom_loss=['Precision'])\n",
    "    '''\n",
    "\n",
    "CatBoost = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    random_seed=random_state,\n",
    "    learning_rate=0.1,\n",
    "    verbose=False,\n",
    "    class_weights=class_weights,\n",
    "    eval_metric='Recall',\n",
    "    custom_loss=['Recall'])\n",
    "\n",
    "    \n",
    "# Train the model on labeled data\n",
    "CatBoost.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_test, y_test),\n",
    "    )\n",
    "\n",
    "cv_params = CatBoost.get_params()\n",
    "cv_params.update({\n",
    "        'loss_function': metrics.Logloss()\n",
    "    })\n",
    "cv_data = cv(\n",
    "        Pool(X_train, y_train, cat_features=categorical_features_indices),\n",
    "        cv_params\n",
    "    )\n",
    "\n",
    "#print(CatBoost.get_feature_importance(prettified=True))\n",
    "\n",
    "# Generate pseudo-labels for unlabeled data using the model\n",
    "pseudo_labels = CatBoost.predict(X_unlabeled)\n",
    "\n",
    "\n",
    "# Combine labeled and unlabeled data with their respective pseudo-labels\n",
    "X_combined = np.concatenate((training_data_final2, X_subset), axis=0)\n",
    "y_combined = np.concatenate((training_labels_new, pseudo_labels), axis=0)\n",
    "\n",
    "# Retrain the model on the combined dataset\n",
    "#CatBoost.fit(X_combined, y_combined, cat_features=categorical_features_indices,verbose=False)\n",
    "    \n",
    "CatBoost.fit(\n",
    "    X_combined, y_combined,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_test, y_test),\n",
    "    )\n",
    "\n",
    "cv_params = CatBoost.get_params()\n",
    "cv_params.update({\n",
    "        'loss_function': metrics.Logloss()\n",
    "    })\n",
    "cv_data = cv(\n",
    "        Pool(X_combined, y_combined, cat_features=categorical_features_indices),\n",
    "        cv_params\n",
    "    )\n",
    "    \n",
    "\n",
    "# Evaluate the performance on the validation set\n",
    "accuracy = CatBoost.score(X_test, y_test)\n",
    "print(\"Accuracy on validation set: \", accuracy)\n",
    "    \n",
    "y_pred_val = CatBoost.predict(X_test)\n",
    "precision = precision_score(y_test, y_pred_val)\n",
    "recall = recall_score(y_test, y_pred_val)\n",
    "print(\"Precision: \", precision, \"Recall: \", recall)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e3d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier, Pool, metrics, cv\n",
    "\n",
    "class_weights = [1,1.5]\n",
    "\n",
    "\n",
    "CatBoost = CatBoostClassifier(\n",
    "    iterations=100,\n",
    "    random_seed=random_state,\n",
    "    learning_rate=0.1,\n",
    "    verbose=False,\n",
    "    class_weights=class_weights,eval_metric='Recall',\n",
    "    custom_loss=['Recall'])\n",
    "\n",
    "num_iterations = 5\n",
    "best_precision = 0.0\n",
    "best_recall = 0.0\n",
    "portion = 0.25\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    \n",
    "    # Calculate the number of unlabeled samples to use based on the portion\n",
    "    num_samples = int(portion * (i + 1) * len(X_unlabeled))\n",
    "    X_subset = X_unlabeled[:num_samples]\n",
    "    \n",
    "    CatBoost.fit(\n",
    "    X_train, y_train,\n",
    "    cat_features=categorical_features_indices,\n",
    "    eval_set=(X_test, y_test),\n",
    "    )\n",
    "    cv_params = CatBoost.get_params()\n",
    "    cv_params.update({\n",
    "        'loss_function': metrics.Logloss()\n",
    "    })\n",
    "    cv_data = cv(\n",
    "        Pool(X_train, y_train, cat_features=categorical_features_indices),\n",
    "        cv_params\n",
    "    )\n",
    "\n",
    "\n",
    "    # Generate pseudo-labels for unlabeled data using the model\n",
    "    \n",
    "    pseudo_labels = CatBoost.predict(X_subset)\n",
    "\n",
    "    # Combine labeled and unlabeled data with their respective pseudo-labels\n",
    "    X_combined = np.concatenate((training_data_final2, X_subset), axis=0)\n",
    "    y_combined = np.concatenate((training_labels_new, pseudo_labels), axis=0)\n",
    "\n",
    "    # Retrain the model on the combined dataset\n",
    "    CatBoost.fit(X_combined, y_combined, cat_features=categorical_features_indices,verbose=False)\n",
    "\n",
    "    # Evaluate the performance on the validation set\n",
    "    accuracy = CatBoost.score(X_test, y_test)\n",
    "    print(\"Iteration\", i+1, \"- Accuracy on validation set:\", accuracy)\n",
    "    \n",
    "    y_pred_val = CatBoost.predict(X_test)\n",
    "    precision = precision_score(y_test, y_pred_val)\n",
    "    recall = recall_score(y_test, y_pred_val)\n",
    "    print(\"Iteration\", i+1, \"- Precision:\", precision, \"- Recall:\", recall)\n",
    "    \n",
    "    # Check for improvement in precision and recall\n",
    "    if precision > best_precision and recall > best_recall:\n",
    "        best_precision = precision\n",
    "        best_recall = recall\n",
    "    '''    \n",
    "    else:\n",
    "        # If precision and recall do not improve, break the loop\n",
    "        print(\"No improvement in precision and recall. Stopping the iterations.\")\n",
    "        break\n",
    "    '''\n",
    "\n",
    "# Print the best precision and recall achieved\n",
    "print(\"Best Precision:\", best_precision, \"- Best Recall:\", best_recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a874250",
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_probs = CatBoost.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Plot the calibration curve\n",
    "true_probs, predicted_probs = calibration_curve(y_test, calibrated_probs, n_bins=10)\n",
    "plt.plot(predicted_probs, true_probs, marker='o', linewidth=1, label='Calibration Curve')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='r', label='Ideal Calibration')\n",
    "plt.xlabel('Predicted probability')\n",
    "plt.ylabel('True probability')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad4b9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check performance\n",
    "predictions = CatBoost.predict(X_test)\n",
    "\n",
    "y_true = y_test.copy()\n",
    "target_names = ['Non TS', 'TS']\n",
    "\n",
    "print(classification_report(y_true, predictions, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b9177",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = CatBoost.predict(X_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fcd1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(final_predictions)\n",
    "print(calc)\n",
    "\n",
    "calc = np.sum(final_predictions==1)\n",
    "print(calc/total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8062c9f",
   "metadata": {},
   "source": [
    "### 5. Make predictions on full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b995d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input .csv file and outputs TS predictions in the 'predictions' folder\n",
    "\n",
    "def predictions(filename):\n",
    "    \n",
    "    testing_data = pd.read_csv('updated_datasets/'+filename)\n",
    "    test_dataset = testing_data\n",
    "    print('Filename: ',filename)\n",
    "    check_jobtitle(test_dataset)\n",
    "    check_company(test_dataset)\n",
    "    check_skills(test_dataset)\n",
    "    check_summary(test_dataset)\n",
    "    check_desc(test_dataset)\n",
    "    check_location(test_dataset)\n",
    "    check_name(test_dataset)\n",
    "    print('Results:')\n",
    "    \n",
    "    test_dataset.fillna({'connections':0, 'company_1':'', 'company_2': '',\n",
    "                    'company_3':'', 'company_4':'NA', 'Summary':'','Skills':'','Job_Description_1':'',\n",
    "                    'First Name':'','Surname':'','State':'','title_1':'',\n",
    "                    'title_2':'', 'Surname':'', 'City':'', 'Country':''}, inplace=True)\n",
    "\n",
    "    test_dataset_final = test_dataset[['job_index', 'company_index','skills_index','summary_index','location_index'\n",
    "                                    ,'name_index','desc_index']]\n",
    "    \n",
    "    \n",
    "    #pred_ts = rfc.predict(test_dataset_final)\n",
    "    #pred_ts = best_model.predict(test_dataset_final)\n",
    "    #pred_ts = mlp['model'].predict(test_dataset_final)\n",
    "    #pred_ts = random_forest['model'].predict(test_dataset_final)\n",
    "    #pred_ts = GBC['model'].predict(test_dataset_final)\n",
    "    \n",
    "    ### For CatBoost Classifiers ###\n",
    "    test_dataset_final2 = test_dataset[catboost_columns]\n",
    "    \n",
    "    pred_ts = CatBoost.predict(test_dataset_final2)\n",
    "    proba = CatBoost.predict_proba(test_dataset_final2)\n",
    "    \n",
    "\n",
    "    \n",
    "    print('number of predicted TS:', np.sum(pred_ts == 1))\n",
    "    rate = np.sum(pred_ts == 1)/len(pred_ts)\n",
    "    print('percentage of predicted TS:', rate)\n",
    "    print()\n",
    "\n",
    "    # write out predictions to csv\n",
    "    output = test_dataset.loc[pred_ts == 1]\n",
    "    proba_df = pd.DataFrame(proba)\n",
    "    output_proba = proba_df.loc[pred_ts == 1, 1]\n",
    "    output['confidence'] = output_proba\n",
    "\n",
    "    output_columns = ['Linkedin_url','Summary', 'Skills', 'title_1',\n",
    "           'company_1', 'time_duration_1', 'Job_Description_1',\n",
    "           'First Name','Middle Name', 'Surname', 'City', 'State', 'Country',\n",
    "           'confidence']\n",
    "\n",
    "    output = output[output_columns]\n",
    "    filename_out = 'predictions/'+filename[:-4]+'__predictions.csv'\n",
    "    output.to_csv(filename_out, index=False)\n",
    "    \n",
    "    return rate, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 629,
   "id": "8b850b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['updated_lifull_12.2022.csv', 'updated_lifull_419M3.csv', 'updated_lifull_419_M2.csv', 'updated_more_training_data.csv', 'updated_lifull_419M1.csv', 'updated_lifull_bing2_212.csv', 'updated_lifull_322_0.csv', 'updated_li_full_11_22.csv', 'updated_lifull_303.csv', 'updated_lifull_326-001.csv', 'updated_lifull_bing1_212.csv', 'updated_lifull_326-000.csv', 'updated_lifull_326-002.csv', 'updated_lifull_reg_212.csv', 'updated_lifull_1_2023.csv', 'updated_lifull_309_1.csv', 'updated_lifull_309_2_3.csv']\n"
     ]
    }
   ],
   "source": [
    "dataset_files = glob.glob('updated_datasets/*.csv')\n",
    "dataset_files = [os.path.basename(file) for file in dataset_files]\n",
    "print(dataset_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6d025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df = []\n",
    "total_rate = []\n",
    "for idx, file in enumerate(dataset_files):\n",
    "    print(idx,' out of ',len(dataset_files)-1)\n",
    "    rate, output = predictions(file)\n",
    "    output_df.append(output)\n",
    "    total_rate.append(rate)\n",
    "\n",
    "# combine all predictions into one file    \n",
    "filename_out = 'predictions/Combined__predictions.csv'\n",
    "combined_df = pd.concat(output_df, ignore_index=True)\n",
    "print(combined_df.shape)\n",
    "print(sum(total_rate)/len(total_rate))\n",
    "#combined_df.to_csv(filename_out, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5b9984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaged Frequency results across all datasets\n",
    "\n",
    "freq_sum = pd.Series()\n",
    "count = 0\n",
    "\n",
    "# Accumulate frequencies and associated companies\n",
    "for output in output_df:\n",
    "    freq = output['company_1'].value_counts().head(25)\n",
    "    freq_sum = freq_sum.add(freq, fill_value=0)\n",
    "    count += 1\n",
    "\n",
    "sorted_freq = freq_sum.sort_values(ascending=False)\n",
    "average_freq = sorted_freq / (count)\n",
    "associated_company = average_freq.idxmax()\n",
    "\n",
    "print(\"Average Frequency:\")\n",
    "print(average_freq[:25])\n",
    "\n",
    "### CatBoost ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "dd9bbe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Booz Allen Hamilton                        142\n",
      "Northrop Grumman                            94\n",
      "L3Harris Technologies                       43\n",
      "United States Air Force                     39\n",
      "CACI International Inc                      28\n",
      "Raytheon Technologies                       26\n",
      "Epic                                        24\n",
      "SAIC                                        18\n",
      "Leidos                                      18\n",
      "Raytheon Intelligence & Space               17\n",
      "Lockheed Martin                             17\n",
      "Amazon Web Services (AWS)                   15\n",
      "Microsoft                                   14\n",
      "General Dynamics Information Technology     13\n",
      "Peraton                                     12\n",
      "ManTech                                     12\n",
      "C3 AI                                       11\n",
      "MITRE                                       11\n",
      "Ball Aerospace                              11\n",
      "PayPal                                      10\n",
      "Qualcomm                                    10\n",
      "Deloitte                                    10\n",
      "General Dynamics Mission Systems             8\n",
      "BlueWater Federal Solutions                  7\n",
      "eBay                                         6\n",
      "BIT Systems                                  6\n",
      "Twilio Inc.                                  6\n",
      "Capital One                                  6\n",
      "Cole Engineering Services, Inc.              5\n",
      "United States Department of Defense          5\n",
      "Name: company_1, dtype: int64\n",
      "1168\n"
     ]
    }
   ],
   "source": [
    "output = output_df[0]\n",
    "freq = output['company_1'].value_counts()\n",
    "print(freq[:30])\n",
    "print(len(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ae102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_freq = output[0,'company_1'].value_counts()\n",
    "\n",
    "#print(original_freq)\n",
    "\n",
    "print(freq['Lockheed Martin']/original_freq['Lockheed Martin'])\n",
    "\n",
    "#print(freq['Microsoft']/original_freq['Microsoft'])\n",
    "#freq['Amazon']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
